# -*- coding: utf-8 -*-
"""Untitled54.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nAVAqqPY2Xg992l6QxFz8vy2VU-zDylu

IMPORTING REQUIRED LIBRARIES
"""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

def create_matrix(text, vectorizer):
    doc_matrix = vectorizer.fit_transform(text)
    return pd.DataFrame(doc_matrix.toarray(),columns = vectorizer.get_feature_names())

messg = ['We are team seven presenting', 'we are pleased to presenting you this topic']

count_vect = CountVectorizer()
create_matrix(messg,count_vect)

tf_idf = TfidfVectorizer()
create_matrix(messg,tf_idf)

import pandas as pd  
import numpy as np
import os
data_folder = "bbc/" # to help while giving path 
os.listdir(data_folder)

files = os.listdir('./bbc/business/') # checking the files inside the business folder
folderslist = [f for f in os.listdir(data_folder)] #creating a list of all subfolders inside bbc folder
folderslist.remove('README.TXT') #removing unwanted file
folderslist # listing out the elements

news = [] # creating a list of news and newstype as those two columns are required in our end result
newstype = [] # and then coverting the list into dataframe
folders = ["business","entertainment","politics","sport","tech"] #this helps to loop over all these folders while reading
#the files in it 
for folder in folders:  # goes into every classes 
    folder_path = './bbc/'+folder+'/'  #path to help get inside the classes
    files = os.listdir(folder_path) #lists the files inside every classes
    for text_file in files: # goes to every file
        file_path = folder_path + "/" +text_file #path to get into file
        with open(file_path, errors='replace') as f: #getting into file
            data = f.readlines() #reading the entire line of data
        data = ' '.join(data) # joining the read lines
        news.append(data) # appending the data in the file to the list
        newstype.append(folder) # appending the class of the file which was read

datadict = {'news':news, 'type':newstype} # creating the dictonary of two list
df = pd.DataFrame(datadict) #converting into dataframe
df.to_csv('./bbc.csv') #saving it into csv

df = pd.read_csv('bbc.csv', index_col=[0]) #reading the downloaded file and looking into data
print(df.shape)
df.head(3)

df.groupby(['type']).agg(['count']) # summary of the data

df['news'] = df['news'].str.replace('\n','') #removing newlines in the data
df.to_csv('new_bbc.csv') # now it is ready to use

df.head(2)

















# Commented out IPython magic to ensure Python compatibility.

import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline
from nltk.stem import PorterStemmer 
from nltk.tokenize import word_tokenize 
import seaborn as sns

data = pd.read_csv('bbc.csv', index_col = [0])
#data.set_index('type', inplace = True)

data.head()